{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extractor(img):\n",
    "    grey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(grey,1.3,3)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        face_crop = img[y:y+h,x:x+w]\n",
    "    \n",
    "    return face_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "no face detected\n",
      "collect finish\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        grey = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name = './face/'+str(count)+'.jpg'\n",
    "        cv2.imwrite(file_name,grey)\n",
    "        \n",
    "        cv2.putText(grey,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2)\n",
    "        cv2.imshow('collect',grey)\n",
    "    \n",
    "    else:\n",
    "        print(\"no face detected\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey() == 13 or count == 100:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"collect finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './face/'\n",
    "files = [f for f in listdir(data_path) if isfile(join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(files):\n",
    "    file_wholename = str(data_path+files[i])\n",
    "    img = cv2.imread(file_wholename,cv2.IMREAD_GRAYSCALE)\n",
    "    training_data.append(np.asarray(img,dtype= np.uint8))\n",
    "    labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels,np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(np.asarray(training_data),np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(img, size = 0.5):\n",
    "    grey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(grey,1.3,3)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi = cv2.resize(img[y:y+h,x:x+w],(200,200))\n",
    "    return img, roi\n",
    "# def face_detector(img, size=0.5):\n",
    "    \n",
    "#     # Convert image to grayscale\n",
    "#     gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "#     if faces is ():\n",
    "#         return img, []\n",
    "    \n",
    "#     for (x,y,w,h) in faces:\n",
    "#         cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "#         roi = img[y:y+h, x:x+w]\n",
    "#         roi = cv2.resize(roi, (200, 200))\n",
    "#     return img, roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.open(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face)\n",
    "        \n",
    "        confidence = int(100*(1-result[1]/400))\n",
    "        if confidence > 70:\n",
    "            cv2.putText(image,'the confidence is '+confidence+' : Unlocked',(50,50),cv2.FONT_HERSHEY_COMPLEX,2,(255,0,0),2)\n",
    "            cv2.imshow('found',image)\n",
    "        else:\n",
    "            cv2.putText(image,'locked',(50,50),cv2.FONT_HERSHEY_COMPLEX,2,(255,0,0),2)\n",
    "            cv2.imshow('found',image)\n",
    "        \n",
    "    except:\n",
    "        cv2.putText(image,'locked',(50,50),cv2.FONT_HERSHEY_COMPLEX,2,(255,0,0),2)\n",
    "        cv2.imshow('not found', image)\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey() == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
