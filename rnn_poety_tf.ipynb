{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    return s.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'roads', 'diverged', 'in', 'a', 'yellow', 'wood']\n",
      "['and', 'sorry', 'i', 'could', 'not', 'travel', 'both']\n",
      "['and', 'be', 'one', 'traveler', 'long', 'i', 'stood']\n",
      "['and', 'looked', 'down', 'one', 'as', 'far', 'as', 'i', 'could']\n",
      "['to', 'where', 'it', 'bent', 'in', 'the', 'undergrowth']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for line in open('data/robert_frost.txt','r', encoding='utf-8'):\n",
    "    l = line.strip().lower()\n",
    "    ret = remove_punctuation(l).split()\n",
    "    print(ret)\n",
    "    i += 1\n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robert():\n",
    "    word2ind = {\"start\":0,\"end\":1}\n",
    "    current_index = 2\n",
    "    sentences = []\n",
    "    for line in open('data/robert_frost.txt','r', encoding='utf-8'):\n",
    "        if line:\n",
    "            l = line.strip().lower()\n",
    "            words = remove_punctuation(l).split()\n",
    "            sentence = []\n",
    "            for word in words:\n",
    "                if word not in word2ind:\n",
    "                    word2ind[word] = current_index\n",
    "                    current_index += 1\n",
    "                idx = word2ind[word]\n",
    "                sentence.append(idx)\n",
    "            \n",
    "        sentences.append(sentence)\n",
    "    return sentences,word2ind\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(Mi, Mo):\n",
    "    return np.random.randn(Mi, Mo) / np.sqrt(Mi + Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(object):\n",
    "    def __init__(self,D,M,V,f,session):\n",
    "        self.D = D # dimension of embedding \n",
    "        self.M = M # dimension of hidden layer\n",
    "        self.V = V # dimension of vocabulary\n",
    "        self.f = f #activation function\n",
    "        self.session = session\n",
    "        \n",
    "    def build(self, we,wx,wh,wo,h0,bh,bo):\n",
    "        self.we = tf.Variable(we)\n",
    "        self.wx = tf.Variable(wx)\n",
    "        self.wh = tf.Variable(wh)\n",
    "        self.wo = tf.Variable(wo)\n",
    "        self.h0 = tf.Variable(h0)\n",
    "        self.bh = tf.Variable(bh)\n",
    "        self.bo = tf.Variable(bo)\n",
    "        self.params = [self.we,self.wx,self.wh,self.wo,self.h0,self.bh,self.bo]\n",
    "        \n",
    "        #ez access\n",
    "        V = self.V\n",
    "        D = self.D\n",
    "        M = self.M\n",
    "        \n",
    "        #placeholder\n",
    "        self.tfX = tf.placeholder(X,shape = (None,),'X')\n",
    "        self.tfY = tf.placeholder(Y,shape = (None,),'Y')\n",
    "        \n",
    "        XW = tf.nn.embedding_lookup(we,self.tfX)\n",
    "        \n",
    "        XW_WX = tf.matmul(XW,self.wx)\n",
    "        \n",
    "        def recurrent(h,xw_wx_t):\n",
    "            h_t = tf.reshape(h,(M,1))\n",
    "            h_new = self.f(xw_wx_t + tf.matmul(h_t,self.wh) + self.bh)\n",
    "            res = tf.reshape(h_new,(M,1))\n",
    "            return res\n",
    "        \n",
    "        h = tf.scan(\n",
    "            fn = recurrent,\n",
    "            elems = XW_WX,\n",
    "            initializer = self.h0\n",
    "        )\n",
    "        \n",
    "        #output\n",
    "        logit = tf.matmul(h, self.wo) + self.bo\n",
    "        prediction = tf.argmax(logit,axis = 1)\n",
    "        self.output_prob = tf.nn.softmax(logit)\n",
    "        \n",
    "        cost_weight = tf.transpose(self.wo,[1,0])\n",
    "        h = tf.reshape(self.h,(-1,M))\n",
    "        labels = tf.reshape(self.tfY,(-1,1))\n",
    "        \n",
    "        self.cost = tf.reduce_mean(\n",
    "            tf.nn.sampled_softmax_loss(\n",
    "                weights = ,\n",
    "                biases = self.b0,\n",
    "                labels = labels ,\n",
    "                inputs = h,\n",
    "                num_sampled = 50,\n",
    "                num_classes = V\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.predict_op = prediction\n",
    "        self.train_op = tf.train.AdadeltaOptimizer(1e-2).minimize(self.cost)\n",
    "        #init variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.session.run(init)\n",
    "    \n",
    "    \n",
    "    def fit(self,X,epi = 500, show_figure = False):\n",
    "        N = len(X)\n",
    "        V = self.V\n",
    "        M = self.M\n",
    "        D = self.D\n",
    "        \n",
    "        #init weights\n",
    "        we = init_weight(np.random.rand(V,D)).astype(np.float32)\n",
    "        wx = init_weight(np.random.rand(D,M)).astype(np.float32)\n",
    "        wh = init_weight(np.random.rand(M,M)).astype(np.float32)\n",
    "        wo = init_weight(np.random.rand(M,K)).astype(np.float32)\n",
    "        \n",
    "        bh = init_weight(np.zeros(M)).astype(np.float32)\n",
    "        bo = init_weight(np.zeros(K)).astype(np.float32)\n",
    "        h0 = init_weight(np.zeros(M)).astype(np.float32)\n",
    "        \n",
    "        self.build(we,wx,wh,wo,h0,bh,bo)\n",
    "        \n",
    "        costs = []\n",
    "        n_total = sum((len(sentence) + 1) for sentence in X)\n",
    "        \n",
    "        for i in range(epi):\n",
    "            X = shuffle(X)\n",
    "            n_correct = 0\n",
    "            cost = 0\n",
    "            \n",
    "            for j in range(N):\n",
    "                \n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self):\n",
    "        pass\n",
    "    \n",
    "    def generate(self):\n",
    "        pass\n",
    "    \n",
    "    def save(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_poety(session,dim,savefile):\n",
    "    sentences,word2ind = get_robert()\n",
    "    rnn = SimpleRNN(dim,dim,len(word2ind),session)\n",
    "    rnn.fit(sentences,epi = 20,show_figure = False)\n",
    "    rnn.save(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemerate_poety(session,savefile):\n",
    "    sentences, word2ind = get_robert()\n",
    "    rnn = SimpleRNN.load(savefile,tf.nn.relu,savefile)\n",
    "    #get the initial word distribution\n",
    "    V = len(sentences)\n",
    "    pi = np.zeros(V)\n",
    "    for s in sentences:\n",
    "        pi[s[0]] += 1\n",
    "    pi = pi/np.sum(pi)\n",
    "    \n",
    "    return rnn.generate(pi,word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c6aabc30aa7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msavefile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rnn_poety.npz'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_poety\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msavefile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mgenerate_poety\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msavefile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-c53c44766e26>\u001b[0m in \u001b[0;36mtrain_poety\u001b[1;34m(session, dim, savefile)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_poety\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msavefile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword2ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_robert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mrnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_figure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavefile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'session'"
     ]
    }
   ],
   "source": [
    "dim = 50\n",
    "savefile = 'rnn_poety.npz'\n",
    "session = tf.InteractiveSession()\n",
    "train_poety(session,dim,savefile)\n",
    "generate_poety(session,savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
