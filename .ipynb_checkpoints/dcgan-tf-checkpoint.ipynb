{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import util\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "beta1 = 0.5\n",
    "batch_size = 64\n",
    "epi = 2\n",
    "save_sample_period = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('samples'):\n",
    "    os.mkdir('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x,alpha = 0.2):\n",
    "    return max(x*alpha,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, name, mi, mo, apply_batch_norm, filter_size = 5, stride = 2, f = tf.nn.relu):\n",
    "        self.W = tf.get_variable(\n",
    "            name = \"W_%s\"%name,\n",
    "            shape = (filter_size, filter_size, mi, mo),\n",
    "            initializer = tf.truncated_normal_initializer(stddev=0.02),\n",
    "        )\n",
    "        \n",
    "        self.b = tf.get_variable(\n",
    "            name = \"b_%s\"%name,\n",
    "            shape=(mo,),\n",
    "            initializer = tf.zeros_initializer(),\n",
    "        )\n",
    "        self.name = name,\n",
    "        self.f = f,\n",
    "        self.stride = stride,\n",
    "        self.apply_batch_norm = apply_batch_norm,\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def forward(self, X, reuse, is_training):\n",
    "        conv_out = tf.nn.conv2d(\n",
    "            X,\n",
    "            self.W,\n",
    "            strides = [1,self.stride,self.stride, 1],\n",
    "            padding = 'SAME'\n",
    "        )\n",
    "        conv_out = tf.nn.bias_add(conv_out,self.b)\n",
    "        \n",
    "        if self.apply_batch_norm:\n",
    "            conv_out = tf.contrib.layers.batch_norm(\n",
    "                conv_out,\n",
    "                decay = 0.9,\n",
    "                updates_collection = None,\n",
    "                epsilon = 1e-5,\n",
    "                scale = True,\n",
    "                is_training = is_training,\n",
    "                reuse = reuse,\n",
    "                scope = self.name,\n",
    "            )\n",
    "        \n",
    "        return self.f(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FractioanllyStridedConvLayer:\n",
    "    def __init__(self, name, mi, mo, output_shape, apply_batch_norm, filter_size = 5, stride = 2, f = tf.nn.relu):\n",
    "        #here the order of mi and mo is reversed\n",
    "        self.W = tf.get_variable(\n",
    "            name = \"W_%s\"%name,\n",
    "            shape = (filter_size, filter_size,mo,mi),\n",
    "            initializer = tf.random_normal_initializer(stddev=0.02),\n",
    "        )\n",
    "        self.b = tf.get_variable(\n",
    "            name = \"b_%s\"%name,\n",
    "            shape = (mo,),\n",
    "            initializer = tf.zeros_initializer(),\n",
    "        )\n",
    "        self.f = f,\n",
    "        self.name = name,\n",
    "        self.output_shape = output_shape,\n",
    "        self.stride = stride,\n",
    "        self.apply_batch_norm = apply_batch_norm,\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def forward(self, X, reuse, is_training):\n",
    "        conv_out = tf.nn.conv2d_transpose(\n",
    "            value = X,\n",
    "            filter = self.W,\n",
    "            output_shape = self.output_shape,\n",
    "            strides = [1,self.stride, self.stride, 1],            \n",
    "        )\n",
    "        \n",
    "        conv_out = tf.nn.bias_add(conv_out,self.b)\n",
    "        \n",
    "        if self.apply_batch_norm:\n",
    "            conv_out = tf.contrib.layers.batch_norm(\n",
    "                conv_out,\n",
    "                decay = 0.9,\n",
    "                updates_collection = None,\n",
    "                epsilon = 1e-5,\n",
    "                scale = True,\n",
    "                is_training = is_training,\n",
    "                reuse = reuse,\n",
    "                scope = self.name,\n",
    "            )\n",
    "        \n",
    "        return self.f(conv_out)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, name, M1, M2, apply_batch_norm, f= tf.nn.relu):\n",
    "        self.W = tf.get_variable(\n",
    "            \"W_%s\"%name,\n",
    "            shape = (M1, M2),\n",
    "            initializer = tf.random_normal_initializer(stddev=0.02),\n",
    "        )\n",
    "        \n",
    "        self.b = tf.get_variable(\n",
    "            \"b_%s\"%name,\n",
    "            shape = (M2,),\n",
    "            initializer = tf.zeros_initializer(),\n",
    "        )\n",
    "        \n",
    "        self.name = name,\n",
    "        self.apply_batch_norm = apply_batch_norm,\n",
    "        self.f = f,\n",
    "        self.params = [self.W, self.b]\n",
    "    \n",
    "    def forward(self, X, reuse, is_training):\n",
    "        a = tf.matmul(X, self.W) + self.b\n",
    "        \n",
    "        if self.apply_batch_norm:\n",
    "            a = tf.contrib.layers.batch_norm(\n",
    "                a,\n",
    "                decay = 0.9,\n",
    "                updates_collection = None,\n",
    "                epsilon = 1e-5,\n",
    "                scale = True,\n",
    "                is_training = is_training,\n",
    "                reuse = reuse,\n",
    "                scope = self.name,\n",
    "            )\n",
    "        return self.f(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self, img_length, num_colors, d_sizes, g_sizes):\n",
    "        self.img_length = img_length,\n",
    "        self.num_colors = num_colors,\n",
    "        self.latent_dims = g_sizes['z']\n",
    "        \n",
    "        self.X = tf.placeholder(\n",
    "            tf.float32,\n",
    "            shape = (None, self.img_length,self.img_length,self.num_colors),\n",
    "            name = 'X',\n",
    "        )\n",
    "        self.Z = tf.placeholder(\n",
    "            tf.float32,\n",
    "            shape = (None, self.latent_dims),\n",
    "            name = 'Z',\n",
    "        )\n",
    "        self.batch_size = tf.placeholder(\n",
    "            tf.float32,\n",
    "            shape=(),\n",
    "            name = 'batch_size',\n",
    "        )\n",
    "        #build discriminator\n",
    "        logits = self.build_discriminator(self.X, d_sizes)\n",
    "        #build generator\n",
    "        self.sample_images = self.build_generator(self.Z,g_sizes)\n",
    "        \n",
    "        with tf.variable_scope(\"discriminator\") as scope:\n",
    "            scope.reuse_variables()\n",
    "            sample_logits = self.d_forward(self.sample_images, True)\n",
    "        \n",
    "        with tf.variable_scope(\"generator\") as scope:\n",
    "            scope.reuse_variables()\n",
    "            self.sample_image_test = self.g_forward(self.Z, reuse = True, is_training = False)\n",
    "        \n",
    "        #build cost\n",
    "        self.d_cost_real = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits = logits,\n",
    "            labels = tf.ones_like(logits)\n",
    "        )\n",
    "        \n",
    "        self.d_cost_fake = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits = sample_logits,\n",
    "            lables = tf.zeros_like(logits)\n",
    "        )\n",
    "        \n",
    "        self.d_cost = tf.reduce_mean(self.d_cost_real) + tf.reduce_mean(self.d_cost_fake)\n",
    "        \n",
    "        self.g_cost = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits = sample_logits,\n",
    "                labels = tf.ones_like(sample_logits)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        real_prediction = tf.cast(logits > 0, tf.float32)\n",
    "        fake_prediction = tf.cast(sample_logits < 0, tf.float32)\n",
    "        num_prediction = 2.0*batch_size\n",
    "        num_correct = tf.reduce_sum(real_prediction) + tf.reduce_sum(fake_prediction)\n",
    "        self.d_accuracy = num_correct/num_prediction\n",
    "        \n",
    "        #optimize\n",
    "        self.d_params = [d for d in tf.trainable_variables() if t.name.startwith('d')]\n",
    "        self.g_params = [g for g in tf.trainable_variables() if t.name.startwith('g')]\n",
    "        \n",
    "        self.d_trainop = tf.train.AdamOptimizer(learning_rate,beta1=beta1).minimize(self.d_cost, var_list = self.d_params)\n",
    "        self.g_trainop = tf.train.AdamOptimizer(learning_rate,beta1=beta1).minimize(self.g_cost, var_list = self.g_params)\n",
    "        \n",
    "        self.initop = tf.global_variables_initializer()\n",
    "        self.s = tf.InteractiveSession()\n",
    "        self.s.run(self.initop)\n",
    "    \n",
    "    def build_discriminator(self, X, d_sizes):\n",
    "        with tf.variable_scope('discriminator') as scope:\n",
    "            \n",
    "            #build conv layer\n",
    "            self.d_convlayers = []\n",
    "            mi = self.num_colors\n",
    "            dim = self.img_length\n",
    "            count = 0\n",
    "            for mo, filter_size, stride, apply_batch_norm in d_sizes['conv_layers']:\n",
    "                name \n",
    "    \n",
    "    def d_forward(self):\n",
    "        pass\n",
    "    \n",
    "    def build_generator(self):\n",
    "        pass\n",
    "    \n",
    "    def g_forward(self):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
